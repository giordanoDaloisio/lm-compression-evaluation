\begin{tabular}{llll}
\toprule
\textbf{Compression Method} & \textbf{Inference Time CPU} & \textbf{Inference Time GPU} & \textbf{Model Size} \\
\midrule
None & 500.380 (sec) & 23.721 (sec) & 707 (MB) \\
Know. Distil. & -43.4\% $\pm$ 6.0\% & 4.2\% $\pm$ 3.8\% & -33.0\% \\
Pruning (0.2) & -51.8\% $\pm$ 4.6\% & 9.5\% $\pm$ 2.1\% & 0.0\% \\
Pruning (0.4) & 22.0\% $\pm$ 13.5\% & 137.5\% $\pm$ 12.8\% & 0.0\% \\
Pruning (0.6) & 236.1\% $\pm$ 48.1\% & 455.8\% $\pm$ 29.3\% & 0.0\% \\
Quantization (float8) & -30.8\% $\pm$ 6.7\% & 13.6\% $\pm$ 2.5\% & -42.0\% \\
Quantization (int4) & 5.8\% $\pm$ 31.6\% & 27.8\% $\pm$ 2.5\% & -51.9\% \\
Quantization (int8) & -35.0\% $\pm$ 6.1\% & 6.2\% $\pm$ 2.3\% & -42.0\% \\
\bottomrule
\end{tabular}
