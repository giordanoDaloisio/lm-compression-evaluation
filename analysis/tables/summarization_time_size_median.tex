\begin{tabular}{llll}
\toprule
\textbf{Compression Method} & \textbf{Inference Time CPU} & \textbf{Inference Time GPU} & \textbf{Model Size} \\
\midrule
None & 157.369 (sec) & 23.692 (sec) & 707 (MB) \\
Know. Distil. & -39.8\% $\pm$ 7.8\% & -2.2\% $\pm$ 4.9\% & -33.0\% \\
Pruning (0.2) & -45.3\% $\pm$ 4.9\% & 9.8\% $\pm$ 1.9\% & 0.0\% \\
Pruning (0.4) & 24.7\% $\pm$ 19.8\% & 121.9\% $\pm$ 13.1\% & 0.0\% \\
Pruning (0.6) & 183.5\% $\pm$ 41.9\% & 419.3\% $\pm$ 29.5\% & 0.0\% \\
Quantization (float8) & -20.3\% $\pm$ 7.9\% & 14.0\% $\pm$ 2.2\% & -42.0\% \\
Quantization (int4) & -17.9\% $\pm$ 7.0\% & 29.1\% $\pm$ 2.5\% & -51.9\% \\
Quantization (int8) & -27.2\% $\pm$ 6.7\% & 6.2\% $\pm$ 2.3\% & -42.0\% \\
\bottomrule
\end{tabular}
