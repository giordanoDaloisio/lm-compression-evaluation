08/29/2024 17:38:38 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
08/29/2024 17:38:38 - DEBUG - urllib3.connectionpool -   Starting new HTTPS connection (1): huggingface.co:443
08/29/2024 17:38:39 - DEBUG - urllib3.connectionpool -   https://huggingface.co:443 "HEAD /microsoft/codebert-base/resolve/main/config.json HTTP/11" 200 0
08/29/2024 17:38:39 - DEBUG - urllib3.connectionpool -   https://huggingface.co:443 "HEAD /roberta-base/resolve/main/tokenizer_config.json HTTP/11" 200 0
08/29/2024 17:38:40 - DEBUG - urllib3.connectionpool -   https://huggingface.co:443 "HEAD /microsoft/codebert-base/resolve/main/model.safetensors HTTP/11" 404 0
08/29/2024 17:38:43 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='../dataset/train_teach.jsonl', output_dir='./saved_models_distil_ase3', eval_data_file='../dataset/valid.jsonl', test_data_file='../dataset/test.jsonl', model_type='roberta', model_name_or_path='microsoft/codebert-base', mlm=False, mlm_probability=0.15, config_name='microsoft/codebert-base', tokenizer_name='roberta-base', cache_dir='', block_size=256, do_train=True, do_eval=False, do_test=False, evaluate_during_training=True, do_lower_case=False, train_batch_size=32, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_steps=50, save_steps=50, save_total_limit=None, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=False, overwrite_cache=False, seed=123456, epoch=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', quantize=False, quantize4=False, quantizef8=False, prune=False, prune4=False, prune6=False, job_id=None, n_gpu=1, device=device(type='cuda'), per_gpu_train_batch_size=32, per_gpu_eval_batch_size=64, start_epoch=0, start_step=0)
08/29/2024 17:41:06 - INFO - __main__ -   *** Example ***
08/29/2024 17:41:06 - INFO - __main__ -   idx: 0
08/29/2024 17:41:06 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_split', '_', 'ph', 'yl', 'ogen', 'y', '_(', '_p', '_,', '_level', '_=', '_"', 's', '"', '_)', '_:', '_level', '_=', '_level', '_+', '_"', '__', '"', '_result', '_=', '_p', '_.', '_split', '_(', '_level', '_)', '_return', '_result', '_[', '_0', '_]', '_+', '_level', '_+', '_result', '_[', '_1', '_]', '_.', '_split', '_(', '_"', ';"', '_)', '_[', '_0', '_]', '</s>']
08/29/2024 17:41:06 - INFO - __main__ -   code_ids: 0 9232 3462 1215 3792 4360 11575 219 36 181 2156 672 5457 22 29 113 4839 4832 672 5457 672 2055 22 30529 113 898 5457 181 479 3462 36 672 4839 671 898 646 321 27779 2055 672 2055 898 646 112 27779 479 3462 36 22 42777 4839 646 321 27779 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
08/29/2024 17:41:06 - INFO - __main__ -   nl_tokens: ['<s>', 'Return', '_either', '_the', '_full', '_or', '_trunc', 'ated', '_version', '_of', '_a', '_Q', 'I', 'IME', '_-', '_formatted', '_tax', 'onomy', '_string', '_.', '</s>']
08/29/2024 17:41:06 - INFO - __main__ -   nl_ids: 0 42555 1169 5 455 50 43064 1070 1732 9 10 1209 100 28417 111 46625 629 38217 6755 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
08/29/2024 17:41:06 - INFO - __main__ -   *** Example ***
08/29/2024 17:41:06 - INFO - __main__ -   idx: 1
08/29/2024 17:41:06 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_ensure', '_', 'dir', '_(', '_d', '_)', '_:', '_if', '_not', '_os', '_.', '_path', '_.', '_exists', '_(', '_d', '_)', '_:', '_try', '_:', '_os', '_.', '_m', 'aked', 'irs', '_(', '_d', '_)', '_except', '_O', 'SE', 'r', 'ror', '_as', '_o', 'e', '_:', '_#', '_should', '_not', '_happen', '_with', '_os', '.', 'm', 'aked', 'irs', '_#', '_EN', 'O', 'ENT', ':', '_No', '_such', '_file', '_or', '_directory', '_if', '_os', '_.', '_err', 'no', '_==', '_err', 'no', '_.', '_EN', 'O', 'ENT', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'One', '_or', '_more', '_directories', '_in', '_the', '_path', '_({', '})', '_do', '_not', '_exist', '.', '_If', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_you', '_are', '_specifying', '_a', '_new', '_directory', '_for', '_output', ',', '_please', '_ensure', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_all', '_other', '_directories', '_in', '_the', '_path', '_currently', '_exist', '."', '""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_)', '_else', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'An', '_error', '_occurred', '_trying', '_to', '_create', '_the', '_output', '_directory', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_({', '})', '_with', '_message', ':', '_{}', '"""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_,', '_o', 'e', '_.', '_stre', 'r', 'ror', '_)', '</s>']
08/29/2024 17:41:06 - INFO - __main__ -   code_ids: 0 9232 1306 1215 41292 36 385 4839 4832 114 45 11988 479 2718 479 8785 36 385 4839 4832 860 4832 11988 479 475 8435 21098 36 385 4839 4682 384 3388 338 21929 25 1021 242 4832 849 197 45 1369 19 11988 4 119 8435 21098 849 13245 673 5382 35 440 215 2870 50 31826 114 11988 479 22379 2362 45994 22379 2362 479 13245 673 5382 4832 49049 5457 11901 16134 36 49434 3762 50 55 44472 11 5 2718 49698 49424 109 45 5152 4 318 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 47 32 39140 10 92 31826 13 4195 6 2540 1306 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 70 97 44472 11 5 2718 855 5152 72 48149 4839 671 49049 479 7390 36 385 4839 1493 4832 49049 5457 11901 16134 36 49434 4688 5849 2756 667 7 1045 5 4195 31826 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 49698 49424 19 1579 35 49153 49849 4839 671 49049 479 7390 36 385 2156 1021 242 479 22246 338 21929 4839 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
08/29/2024 17:41:06 - INFO - __main__ -   nl_tokens: ['<s>', 'Check', '_to', '_make', '_sure', '_the', '_supplied', '_directory', '_path', '_does', '_not', '_exist', '_if', '_so', '_create', '_it', '_.', '_The', '_method', '_catches', '_O', 'SE', 'r', 'ror', '_exceptions', '_and', '_returns', '_a', '_descriptive', '_message', '_instead', '_of', '_re', '_-', '_raising', '_the', '_error', '_.', '</s>']
08/29/2024 17:41:06 - INFO - __main__ -   nl_ids: 0 26615 7 146 686 5 12359 31826 2718 473 45 5152 114 98 1045 24 479 20 5448 8758 384 3388 338 21929 18286 8 2886 10 42690 1579 1386 9 769 111 3282 5 5849 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
08/29/2024 17:41:06 - INFO - __main__ -   *** Example ***
08/29/2024 17:41:06 - INFO - __main__ -   idx: 2
08/29/2024 17:41:06 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_file', '_', 'handle', '_(', '_fn', 'h', '_,', '_mode', '_=', '_"', 'r', 'U', '"', '_)', '_:', '_handle', '_=', '_None', '_if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_file', '_)', '_:', '_if', '_fn', 'h', '_.', '_closed', '_:', '_raise', '_Value', 'Error', '_(', '_"', 'Input', '_file', '_is', '_closed', '."', '_)', '_handle', '_=', '_fn', 'h', '_el', 'if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_str', '_)', '_:', '_handle', '_=', '_open', '_(', '_fn', 'h', '_,', '_mode', '_)', '_return', '_handle', '</s>']
08/29/2024 17:41:06 - INFO - __main__ -   code_ids: 0 9232 2870 1215 26628 36 48930 298 2156 5745 5457 22 338 791 113 4839 4832 3679 5457 9291 114 16 48768 36 48930 298 2156 2870 4839 4832 114 48930 298 479 1367 4832 1693 11714 30192 36 22 48214 2870 16 1367 72 4839 3679 5457 48930 298 1615 1594 16 48768 36 48930 298 2156 7031 4839 4832 3679 5457 490 36 48930 298 2156 5745 4839 671 3679 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
08/29/2024 17:41:06 - INFO - __main__ -   nl_tokens: ['<s>', 'T', 'akes', '_either', '_a', '_file', '_path', '_or', '_an', '_open', '_file', '_handle', '_checks', '_validity', '_and', '_returns', '_an', '_open', '_file', '_handle', '_or', '_raises', '_an', '_appropriate', '_Exception', '_.', '</s>']
08/29/2024 17:41:06 - INFO - __main__ -   nl_ids: 0 565 5556 1169 10 2870 2718 50 41 490 2870 3679 6240 25295 8 2886 41 490 2870 3679 50 7700 41 3901 47617 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
08/29/2024 17:41:13 - INFO - __main__ -   ***** Running training *****
08/29/2024 17:41:13 - INFO - __main__ -     Num examples = 125910
08/29/2024 17:41:13 - INFO - __main__ -     Num Epochs = 2
08/29/2024 17:41:13 - INFO - __main__ -     Instantaneous batch size per GPU = 32
08/29/2024 17:41:13 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
08/29/2024 17:41:13 - INFO - __main__ -     Gradient Accumulation steps = 1
08/29/2024 17:41:13 - INFO - __main__ -     Total optimization steps = 7870
08/29/2024 17:48:04 - INFO - __main__ -   epoch 0 step 100 loss 9.9571
08/29/2024 17:54:50 - INFO - __main__ -   epoch 0 step 200 loss 5.88587
08/29/2024 18:01:36 - INFO - __main__ -   epoch 0 step 300 loss 4.05084
08/29/2024 18:08:03 - INFO - __main__ -   ***** Running evaluation *****
08/29/2024 18:08:03 - INFO - __main__ -     Num examples = 9604
08/29/2024 18:08:03 - INFO - __main__ -     Batch size = 64
08/29/2024 18:15:10 - INFO - __main__ -     eval_loss = 1.3673
08/29/2024 18:15:10 - INFO - __main__ -     eval_mrr = 0.2813
08/29/2024 18:15:10 - INFO - __main__ -     ********************
08/29/2024 18:15:10 - INFO - __main__ -     Best mrr:0.2813
08/29/2024 18:15:10 - INFO - __main__ -     ********************
08/29/2024 18:15:12 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_ase3/checkpoint-best-mrr/model.bin
08/29/2024 18:15:40 - INFO - __main__ -   epoch 0 step 400 loss 0.20773
08/29/2024 18:22:25 - INFO - __main__ -   epoch 0 step 500 loss 0.25399
08/29/2024 18:29:11 - INFO - __main__ -   epoch 0 step 600 loss 0.24219
08/29/2024 18:35:57 - INFO - __main__ -   epoch 0 step 700 loss 0.24683
08/29/2024 18:41:47 - INFO - __main__ -   ***** Running evaluation *****
08/29/2024 18:41:47 - INFO - __main__ -     Num examples = 9604
08/29/2024 18:41:47 - INFO - __main__ -     Batch size = 64
08/29/2024 18:48:57 - INFO - __main__ -     eval_loss = 1.2508
08/29/2024 18:48:57 - INFO - __main__ -     eval_mrr = 0.3083
08/29/2024 18:48:57 - INFO - __main__ -     ********************
08/29/2024 18:48:57 - INFO - __main__ -     Best mrr:0.3083
08/29/2024 18:48:57 - INFO - __main__ -     ********************
08/29/2024 18:48:59 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_ase3/checkpoint-best-mrr/model.bin
08/29/2024 18:49:56 - INFO - __main__ -   epoch 0 step 800 loss 0.19009
08/29/2024 18:56:47 - INFO - __main__ -   epoch 0 step 900 loss 0.23662
08/29/2024 19:03:38 - INFO - __main__ -   epoch 0 step 1000 loss 0.24335
08/29/2024 19:10:29 - INFO - __main__ -   epoch 0 step 1100 loss 0.23554
08/29/2024 19:15:53 - INFO - __main__ -   ***** Running evaluation *****
08/29/2024 19:15:53 - INFO - __main__ -     Num examples = 9604
08/29/2024 19:15:53 - INFO - __main__ -     Batch size = 64
08/29/2024 19:23:07 - INFO - __main__ -     eval_loss = 1.6769
08/29/2024 19:23:07 - INFO - __main__ -     eval_mrr = 0.2389
08/29/2024 19:24:34 - INFO - __main__ -   epoch 0 step 1200 loss 0.26728
08/29/2024 19:31:25 - INFO - __main__ -   epoch 0 step 1300 loss 0.21986
08/29/2024 19:38:15 - INFO - __main__ -   epoch 0 step 1400 loss 0.21275
08/29/2024 19:45:06 - INFO - __main__ -   epoch 0 step 1500 loss 0.20273
08/29/2024 19:50:01 - INFO - __main__ -   ***** Running evaluation *****
08/29/2024 19:50:01 - INFO - __main__ -     Num examples = 9604
08/29/2024 19:50:01 - INFO - __main__ -     Batch size = 64
08/29/2024 19:57:15 - INFO - __main__ -     eval_loss = 1.3342
08/29/2024 19:57:15 - INFO - __main__ -     eval_mrr = 0.2566
08/29/2024 19:59:10 - INFO - __main__ -   epoch 0 step 1600 loss 0.25512
08/29/2024 20:06:00 - INFO - __main__ -   epoch 0 step 1700 loss 0.20798
08/29/2024 20:12:51 - INFO - __main__ -   epoch 0 step 1800 loss 0.20251
08/29/2024 20:19:42 - INFO - __main__ -   epoch 0 step 1900 loss 0.19665
08/29/2024 20:24:09 - INFO - __main__ -   ***** Running evaluation *****
08/29/2024 20:24:09 - INFO - __main__ -     Num examples = 9604
08/29/2024 20:24:09 - INFO - __main__ -     Batch size = 64
08/29/2024 20:31:25 - INFO - __main__ -     eval_loss = 1.4098
08/29/2024 20:31:25 - INFO - __main__ -     eval_mrr = 0.2509
08/29/2024 20:33:47 - INFO - __main__ -   epoch 0 step 2000 loss 0.22554
08/29/2024 20:40:34 - INFO - __main__ -   epoch 0 step 2100 loss 0.19143
08/29/2024 20:47:22 - INFO - __main__ -   epoch 0 step 2200 loss 0.19304
08/29/2024 20:54:08 - INFO - __main__ -   epoch 0 step 2300 loss 0.18116
08/29/2024 20:58:03 - INFO - __main__ -   ***** Running evaluation *****
08/29/2024 20:58:03 - INFO - __main__ -     Num examples = 9604
08/29/2024 20:58:03 - INFO - __main__ -     Batch size = 64
08/29/2024 21:05:12 - INFO - __main__ -     eval_loss = 1.368
08/29/2024 21:05:12 - INFO - __main__ -     eval_mrr = 0.2907
08/29/2024 21:08:03 - INFO - __main__ -   epoch 0 step 2400 loss 0.17354
08/29/2024 21:14:49 - INFO - __main__ -   epoch 0 step 2500 loss 0.1831
08/29/2024 21:21:35 - INFO - __main__ -   epoch 0 step 2600 loss 0.1781
08/29/2024 21:28:21 - INFO - __main__ -   epoch 0 step 2700 loss 0.17631
08/29/2024 21:31:48 - INFO - __main__ -   ***** Running evaluation *****
08/29/2024 21:31:48 - INFO - __main__ -     Num examples = 9604
08/29/2024 21:31:48 - INFO - __main__ -     Batch size = 64
08/29/2024 21:38:57 - INFO - __main__ -     eval_loss = 1.7105
08/29/2024 21:38:57 - INFO - __main__ -     eval_mrr = 0.2674
08/29/2024 21:42:16 - INFO - __main__ -   epoch 0 step 2800 loss 0.17696
08/29/2024 21:49:02 - INFO - __main__ -   epoch 0 step 2900 loss 0.16814
08/29/2024 21:55:48 - INFO - __main__ -   epoch 0 step 3000 loss 0.17254
08/29/2024 22:02:34 - INFO - __main__ -   epoch 0 step 3100 loss 0.17705
08/29/2024 22:05:33 - INFO - __main__ -   ***** Running evaluation *****
08/29/2024 22:05:33 - INFO - __main__ -     Num examples = 9604
08/29/2024 22:05:33 - INFO - __main__ -     Batch size = 64
08/29/2024 22:12:41 - INFO - __main__ -     eval_loss = 1.4292
08/29/2024 22:12:41 - INFO - __main__ -     eval_mrr = 0.263
08/29/2024 22:16:29 - INFO - __main__ -   epoch 0 step 3200 loss 0.15575
08/29/2024 22:23:15 - INFO - __main__ -   epoch 0 step 3300 loss 0.15388
08/29/2024 22:30:00 - INFO - __main__ -   epoch 0 step 3400 loss 0.1496
08/29/2024 22:36:46 - INFO - __main__ -   epoch 0 step 3500 loss 0.15555
08/29/2024 22:39:16 - INFO - __main__ -   ***** Running evaluation *****
08/29/2024 22:39:16 - INFO - __main__ -     Num examples = 9604
08/29/2024 22:39:16 - INFO - __main__ -     Batch size = 64
08/29/2024 22:46:27 - INFO - __main__ -     eval_loss = 1.1974
08/29/2024 22:46:27 - INFO - __main__ -     eval_mrr = 0.3196
08/29/2024 22:46:27 - INFO - __main__ -     ********************
08/29/2024 22:46:27 - INFO - __main__ -     Best mrr:0.3196
08/29/2024 22:46:27 - INFO - __main__ -     ********************
08/29/2024 22:46:29 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_ase3/checkpoint-best-mrr/model.bin
08/29/2024 22:50:45 - INFO - __main__ -   epoch 0 step 3600 loss 0.14316
08/29/2024 22:57:31 - INFO - __main__ -   epoch 0 step 3700 loss 0.14034
08/29/2024 23:04:19 - INFO - __main__ -   epoch 0 step 3800 loss 0.14518
08/29/2024 23:11:06 - INFO - __main__ -   epoch 0 step 3900 loss 0.14301
08/29/2024 23:13:08 - INFO - __main__ -   ***** Running evaluation *****
08/29/2024 23:13:08 - INFO - __main__ -     Num examples = 9604
08/29/2024 23:13:08 - INFO - __main__ -     Batch size = 64
08/29/2024 23:20:17 - INFO - __main__ -     eval_loss = 1.2098
08/29/2024 23:20:17 - INFO - __main__ -     eval_mrr = 0.3261
08/29/2024 23:20:17 - INFO - __main__ -     ********************
08/29/2024 23:20:17 - INFO - __main__ -     Best mrr:0.3261
08/29/2024 23:20:17 - INFO - __main__ -     ********************
08/29/2024 23:20:19 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_ase3/checkpoint-best-mrr/model.bin
08/29/2024 23:27:24 - INFO - __main__ -   epoch 1 step 100 loss 0.08387
08/29/2024 23:34:10 - INFO - __main__ -   epoch 1 step 200 loss 0.08434
08/29/2024 23:40:56 - INFO - __main__ -   epoch 1 step 300 loss 0.08851
08/29/2024 23:46:53 - INFO - __main__ -   ***** Running evaluation *****
08/29/2024 23:46:53 - INFO - __main__ -     Num examples = 9604
08/29/2024 23:46:53 - INFO - __main__ -     Batch size = 64
08/29/2024 23:54:01 - INFO - __main__ -     eval_loss = 1.3211
08/29/2024 23:54:01 - INFO - __main__ -     eval_mrr = 0.3136
08/29/2024 23:54:49 - INFO - __main__ -   epoch 1 step 400 loss 0.05033
08/30/2024 00:01:35 - INFO - __main__ -   epoch 1 step 500 loss 0.08187
08/30/2024 00:08:20 - INFO - __main__ -   epoch 1 step 600 loss 0.0883
08/30/2024 00:15:06 - INFO - __main__ -   epoch 1 step 700 loss 0.0914
08/30/2024 00:20:34 - INFO - __main__ -   ***** Running evaluation *****
08/30/2024 00:20:34 - INFO - __main__ -     Num examples = 9604
08/30/2024 00:20:34 - INFO - __main__ -     Batch size = 64
08/30/2024 00:27:43 - INFO - __main__ -     eval_loss = 1.3287
08/30/2024 00:27:43 - INFO - __main__ -     eval_mrr = 0.3024
08/30/2024 00:29:00 - INFO - __main__ -   epoch 1 step 800 loss 0.0913
08/30/2024 00:35:45 - INFO - __main__ -   epoch 1 step 900 loss 0.08851
08/30/2024 00:42:31 - INFO - __main__ -   epoch 1 step 1000 loss 0.08585
08/30/2024 00:49:16 - INFO - __main__ -   epoch 1 step 1100 loss 0.08718
08/30/2024 00:54:16 - INFO - __main__ -   ***** Running evaluation *****
08/30/2024 00:54:16 - INFO - __main__ -     Num examples = 9604
08/30/2024 00:54:16 - INFO - __main__ -     Batch size = 64
08/30/2024 01:01:27 - INFO - __main__ -     eval_loss = 1.3188
08/30/2024 01:01:27 - INFO - __main__ -     eval_mrr = 0.3364
08/30/2024 01:01:27 - INFO - __main__ -     ********************
08/30/2024 01:01:27 - INFO - __main__ -     Best mrr:0.3364
08/30/2024 01:01:27 - INFO - __main__ -     ********************
08/30/2024 01:01:29 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_ase3/checkpoint-best-mrr/model.bin
08/30/2024 01:03:15 - INFO - __main__ -   epoch 1 step 1200 loss 0.06676
08/30/2024 01:10:02 - INFO - __main__ -   epoch 1 step 1300 loss 0.07012
08/30/2024 01:16:47 - INFO - __main__ -   epoch 1 step 1400 loss 0.0689
08/30/2024 01:23:32 - INFO - __main__ -   epoch 1 step 1500 loss 0.0755
08/30/2024 01:28:04 - INFO - __main__ -   ***** Running evaluation *****
08/30/2024 01:28:04 - INFO - __main__ -     Num examples = 9604
08/30/2024 01:28:04 - INFO - __main__ -     Batch size = 64
08/30/2024 01:35:12 - INFO - __main__ -     eval_loss = 1.2279
08/30/2024 01:35:12 - INFO - __main__ -     eval_mrr = 0.3571
08/30/2024 01:35:12 - INFO - __main__ -     ********************
08/30/2024 01:35:12 - INFO - __main__ -     Best mrr:0.3571
08/30/2024 01:35:12 - INFO - __main__ -     ********************
08/30/2024 01:35:14 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_ase3/checkpoint-best-mrr/model.bin
08/30/2024 01:37:27 - INFO - __main__ -   epoch 1 step 1600 loss 0.06152
08/30/2024 01:44:13 - INFO - __main__ -   epoch 1 step 1700 loss 0.0827
08/30/2024 01:50:59 - INFO - __main__ -   epoch 1 step 1800 loss 0.08657
08/30/2024 01:57:44 - INFO - __main__ -   epoch 1 step 1900 loss 0.08124
08/30/2024 02:01:48 - INFO - __main__ -   ***** Running evaluation *****
08/30/2024 02:01:48 - INFO - __main__ -     Num examples = 9604
08/30/2024 02:01:48 - INFO - __main__ -     Batch size = 64
08/30/2024 02:08:57 - INFO - __main__ -     eval_loss = 1.2573
08/30/2024 02:08:57 - INFO - __main__ -     eval_mrr = 0.3486
08/30/2024 02:11:39 - INFO - __main__ -   epoch 1 step 2000 loss 0.05574
08/30/2024 02:18:25 - INFO - __main__ -   epoch 1 step 2100 loss 0.07306
08/30/2024 02:25:11 - INFO - __main__ -   epoch 1 step 2200 loss 0.06999
08/30/2024 02:31:56 - INFO - __main__ -   epoch 1 step 2300 loss 0.06918
08/30/2024 02:35:32 - INFO - __main__ -   ***** Running evaluation *****
08/30/2024 02:35:32 - INFO - __main__ -     Num examples = 9604
08/30/2024 02:35:32 - INFO - __main__ -     Batch size = 64
08/30/2024 02:42:41 - INFO - __main__ -     eval_loss = 1.2372
08/30/2024 02:42:41 - INFO - __main__ -     eval_mrr = 0.3548
08/30/2024 02:45:51 - INFO - __main__ -   epoch 1 step 2400 loss 0.06926
08/30/2024 02:52:37 - INFO - __main__ -   epoch 1 step 2500 loss 0.06747
08/30/2024 02:59:23 - INFO - __main__ -   epoch 1 step 2600 loss 0.07325
08/30/2024 03:06:10 - INFO - __main__ -   epoch 1 step 2700 loss 0.07374
08/30/2024 03:09:16 - INFO - __main__ -   ***** Running evaluation *****
08/30/2024 03:09:16 - INFO - __main__ -     Num examples = 9604
08/30/2024 03:09:16 - INFO - __main__ -     Batch size = 64
08/30/2024 03:16:25 - INFO - __main__ -     eval_loss = 1.2209
08/30/2024 03:16:25 - INFO - __main__ -     eval_mrr = 0.3582
08/30/2024 03:16:25 - INFO - __main__ -     ********************
08/30/2024 03:16:25 - INFO - __main__ -     Best mrr:0.3582
08/30/2024 03:16:25 - INFO - __main__ -     ********************
08/30/2024 03:16:27 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_ase3/checkpoint-best-mrr/model.bin
08/30/2024 03:20:06 - INFO - __main__ -   epoch 1 step 2800 loss 0.07449
08/30/2024 03:26:52 - INFO - __main__ -   epoch 1 step 2900 loss 0.06257
08/30/2024 03:33:38 - INFO - __main__ -   epoch 1 step 3000 loss 0.06981
08/30/2024 03:40:25 - INFO - __main__ -   epoch 1 step 3100 loss 0.07464
08/30/2024 03:43:03 - INFO - __main__ -   ***** Running evaluation *****
08/30/2024 03:43:03 - INFO - __main__ -     Num examples = 9604
08/30/2024 03:43:03 - INFO - __main__ -     Batch size = 64
08/30/2024 03:50:14 - INFO - __main__ -     eval_loss = 1.2404
08/30/2024 03:50:14 - INFO - __main__ -     eval_mrr = 0.3539
08/30/2024 03:54:22 - INFO - __main__ -   epoch 1 step 3200 loss 0.04926
08/30/2024 04:01:07 - INFO - __main__ -   epoch 1 step 3300 loss 0.06571
08/30/2024 04:07:52 - INFO - __main__ -   epoch 1 step 3400 loss 0.06327
08/30/2024 04:14:37 - INFO - __main__ -   epoch 1 step 3500 loss 0.06234
08/30/2024 04:16:47 - INFO - __main__ -   ***** Running evaluation *****
08/30/2024 04:16:47 - INFO - __main__ -     Num examples = 9604
08/30/2024 04:16:47 - INFO - __main__ -     Batch size = 64
08/30/2024 04:23:57 - INFO - __main__ -     eval_loss = 1.2436
08/30/2024 04:23:57 - INFO - __main__ -     eval_mrr = 0.3557
08/30/2024 04:28:33 - INFO - __main__ -   epoch 1 step 3600 loss 0.0855
08/30/2024 04:35:19 - INFO - __main__ -   epoch 1 step 3700 loss 0.08733
08/30/2024 04:42:05 - INFO - __main__ -   epoch 1 step 3800 loss 0.07479
08/30/2024 04:48:50 - INFO - __main__ -   epoch 1 step 3900 loss 0.07146
08/30/2024 04:50:32 - INFO - __main__ -   ***** Running evaluation *****
08/30/2024 04:50:32 - INFO - __main__ -     Num examples = 9604
08/30/2024 04:50:32 - INFO - __main__ -     Batch size = 64
08/30/2024 04:57:40 - INFO - __main__ -     eval_loss = 1.2406
08/30/2024 04:57:40 - INFO - __main__ -     eval_mrr = 0.356
