No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'
08/29/2024 16:02:03 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 1, distributed training: False, 16-bits training: False
08/29/2024 16:02:05 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='../dataset/train.jsonl', output_dir='./saved_models_distil_ase_3', eval_data_file='../dataset/valid.jsonl', test_data_file='../dataset/test.jsonl', model_type='roberta', model_name_or_path='microsoft/codebert-base', model=None, mlm=False, mlm_probability=0.15, config_name='', tokenizer_name='microsoft/codebert-base', cache_dir='', block_size=400, do_train=False, do_eval=True, do_test=True, evaluate_during_training=True, do_lower_case=False, train_batch_size=32, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_steps=50, save_steps=50, save_total_limit=None, eval_all_checkpoints=False, no_cuda=True, overwrite_output_dir=False, overwrite_cache=False, seed=123456, epoch=5, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', early_stopping_patience=None, min_loss_delta=0.001, dropout_probability=0, job_id='147270', quantize_dynamic=False, quantize_static=False, quantize=False, quantize4=False, quantizef8=False, prune_local=False, prune6=False, prune4=False, prune=False, attention_heads=8, hidden_dim=96, intermediate_size=64, n_layers=12, vocab_size=1000, n_gpu=1, per_gpu_train_batch_size=32, per_gpu_eval_batch_size=64, device=device(type='cpu'), start_epoch=0, start_step=0)
08/29/2024 16:02:05 - INFO - __main__ -   Size (MB): 3.09374
==========================================================================================
Layer (type:depth-idx)                                            Param #
==========================================================================================
Model                                                             --
├─RobertaForSequenceClassification: 1-1                           --
│    └─roberta.embeddings.word_embeddings.weight                  ├─96,000
│    └─roberta.embeddings.position_embeddings.weight              ├─49,344
│    └─roberta.embeddings.token_type_embeddings.weight            ├─96
│    └─roberta.embeddings.LayerNorm.weight                        ├─96
│    └─roberta.embeddings.LayerNorm.bias                          ├─96
│    └─roberta.encoder.layer.0.attention.self.query.weight        ├─9,216
│    └─roberta.encoder.layer.0.attention.self.query.bias          ├─96
│    └─roberta.encoder.layer.0.attention.self.key.weight          ├─9,216
│    └─roberta.encoder.layer.0.attention.self.key.bias            ├─96
│    └─roberta.encoder.layer.0.attention.self.value.weight        ├─9,216
│    └─roberta.encoder.layer.0.attention.self.value.bias          ├─96
│    └─roberta.encoder.layer.0.attention.output.dense.weight      ├─9,216
│    └─roberta.encoder.layer.0.attention.output.dense.bias        ├─96
│    └─roberta.encoder.layer.0.attention.output.LayerNorm.weight  ├─96
│    └─roberta.encoder.layer.0.attention.output.LayerNorm.bias    ├─96
│    └─roberta.encoder.layer.0.intermediate.dense.weight          ├─6,144
│    └─roberta.encoder.layer.0.intermediate.dense.bias            ├─64
│    └─roberta.encoder.layer.0.output.dense.weight                ├─6,144
│    └─roberta.encoder.layer.0.output.dense.bias                  ├─96
│    └─roberta.encoder.layer.0.output.LayerNorm.weight            ├─96
│    └─roberta.encoder.layer.0.output.LayerNorm.bias              ├─96
│    └─roberta.encoder.layer.1.attention.self.query.weight        ├─9,216
│    └─roberta.encoder.layer.1.attention.self.query.bias          ├─96
│    └─roberta.encoder.layer.1.attention.self.key.weight          ├─9,216
│    └─roberta.encoder.layer.1.attention.self.key.bias            ├─96
│    └─roberta.encoder.layer.1.attention.self.value.weight        ├─9,216
│    └─roberta.encoder.layer.1.attention.self.value.bias          ├─96
│    └─roberta.encoder.layer.1.attention.output.dense.weight      ├─9,216
│    └─roberta.encoder.layer.1.attention.output.dense.bias        ├─96
│    └─roberta.encoder.layer.1.attention.output.LayerNorm.weight  ├─96
│    └─roberta.encoder.layer.1.attention.output.LayerNorm.bias    ├─96
│    └─roberta.encoder.layer.1.intermediate.dense.weight          ├─6,144
│    └─roberta.encoder.layer.1.intermediate.dense.bias            ├─64
│    └─roberta.encoder.layer.1.output.dense.weight                ├─6,144
│    └─roberta.encoder.layer.1.output.dense.bias                  ├─96
│    └─roberta.encoder.layer.1.output.LayerNorm.weight            ├─96
│    └─roberta.encoder.layer.1.output.LayerNorm.bias              ├─96
│    └─roberta.encoder.layer.2.attention.self.query.weight        ├─9,216
│    └─roberta.encoder.layer.2.attention.self.query.bias          ├─96
│    └─roberta.encoder.layer.2.attention.self.key.weight          ├─9,216
│    └─roberta.encoder.layer.2.attention.self.key.bias            ├─96
│    └─roberta.encoder.layer.2.attention.self.value.weight        ├─9,216
│    └─roberta.encoder.layer.2.attention.self.value.bias          ├─96
│    └─roberta.encoder.layer.2.attention.output.dense.weight      ├─9,216
│    └─roberta.encoder.layer.2.attention.output.dense.bias        ├─96
│    └─roberta.encoder.layer.2.attention.output.LayerNorm.weight  ├─96
│    └─roberta.encoder.layer.2.attention.output.LayerNorm.bias    ├─96
│    └─roberta.encoder.layer.2.intermediate.dense.weight          ├─6,144
│    └─roberta.encoder.layer.2.intermediate.dense.bias            ├─64
│    └─roberta.encoder.layer.2.output.dense.weight                ├─6,144
│    └─roberta.encoder.layer.2.output.dense.bias                  ├─96
│    └─roberta.encoder.layer.2.output.LayerNorm.weight            ├─96
│    └─roberta.encoder.layer.2.output.LayerNorm.bias              ├─96
│    └─roberta.encoder.layer.3.attention.self.query.weight        ├─9,216
│    └─roberta.encoder.layer.3.attention.self.query.bias          ├─96
│    └─roberta.encoder.layer.3.attention.self.key.weight          ├─9,216
│    └─roberta.encoder.layer.3.attention.self.key.bias            ├─96
│    └─roberta.encoder.layer.3.attention.self.value.weight        ├─9,216
│    └─roberta.encoder.layer.3.attention.self.value.bias          ├─96
│    └─roberta.encoder.layer.3.attention.output.dense.weight      ├─9,216
│    └─roberta.encoder.layer.3.attention.output.dense.bias        ├─96
│    └─roberta.encoder.layer.3.attention.output.LayerNorm.weight  ├─96
│    └─roberta.encoder.layer.3.attention.output.LayerNorm.bias    ├─96
│    └─roberta.encoder.layer.3.intermediate.dense.weight          ├─6,144
│    └─roberta.encoder.layer.3.intermediate.dense.bias            ├─64
│    └─roberta.encoder.layer.3.output.dense.weight                ├─6,144
│    └─roberta.encoder.layer.3.output.dense.bias                  ├─96
│    └─roberta.encoder.layer.3.output.LayerNorm.weight            ├─96
│    └─roberta.encoder.layer.3.output.LayerNorm.bias              ├─96
│    └─roberta.encoder.layer.4.attention.self.query.weight        ├─9,216
│    └─roberta.encoder.layer.4.attention.self.query.bias          ├─96
│    └─roberta.encoder.layer.4.attention.self.key.weight          ├─9,216
│    └─roberta.encoder.layer.4.attention.self.key.bias            ├─96
│    └─roberta.encoder.layer.4.attention.self.value.weight        ├─9,216
│    └─roberta.encoder.layer.4.attention.self.value.bias          ├─96
│    └─roberta.encoder.layer.4.attention.output.dense.weight      ├─9,216
│    └─roberta.encoder.layer.4.attention.output.dense.bias        ├─96
│    └─roberta.encoder.layer.4.attention.output.LayerNorm.weight  ├─96
│    └─roberta.encoder.layer.4.attention.output.LayerNorm.bias    ├─96
│    └─roberta.encoder.layer.4.intermediate.dense.weight          ├─6,144
│    └─roberta.encoder.layer.4.intermediate.dense.bias            ├─64
│    └─roberta.encoder.layer.4.output.dense.weight                ├─6,144
│    └─roberta.encoder.layer.4.output.dense.bias                  ├─96
│    └─roberta.encoder.layer.4.output.LayerNorm.weight            ├─96
│    └─roberta.encoder.layer.4.output.LayerNorm.bias              ├─96
│    └─roberta.encoder.layer.5.attention.self.query.weight        ├─9,216
│    └─roberta.encoder.layer.5.attention.self.query.bias          ├─96
│    └─roberta.encoder.layer.5.attention.self.key.weight          ├─9,216
│    └─roberta.encoder.layer.5.attention.self.key.bias            ├─96
│    └─roberta.encoder.layer.5.attention.self.value.weight        ├─9,216
│    └─roberta.encoder.layer.5.attention.self.value.bias          ├─96
│    └─roberta.encoder.layer.5.attention.output.dense.weight      ├─9,216
│    └─roberta.encoder.layer.5.attention.output.dense.bias        ├─96
│    └─roberta.encoder.layer.5.attention.output.LayerNorm.weight  ├─96
│    └─roberta.encoder.layer.5.attention.output.LayerNorm.bias    ├─96
│    └─roberta.encoder.layer.5.intermediate.dense.weight          ├─6,144
│    └─roberta.encoder.layer.5.intermediate.dense.bias            ├─64
│    └─roberta.encoder.layer.5.output.dense.weight                ├─6,144
│    └─roberta.encoder.layer.5.output.dense.bias                  ├─96
│    └─roberta.encoder.layer.5.output.LayerNorm.weight            ├─96
│    └─roberta.encoder.layer.5.output.LayerNorm.bias              ├─96
│    └─roberta.encoder.layer.6.attention.self.query.weight        ├─9,216
│    └─roberta.encoder.layer.6.attention.self.query.bias          ├─96
│    └─roberta.encoder.layer.6.attention.self.key.weight          ├─9,216
│    └─roberta.encoder.layer.6.attention.self.key.bias            ├─96
│    └─roberta.encoder.layer.6.attention.self.value.weight        ├─9,216
│    └─roberta.encoder.layer.6.attention.self.value.bias          ├─96
│    └─roberta.encoder.layer.6.attention.output.dense.weight      ├─9,216
│    └─roberta.encoder.layer.6.attention.output.dense.bias        ├─96
│    └─roberta.encoder.layer.6.attention.output.LayerNorm.weight  ├─96
│    └─roberta.encoder.layer.6.attention.output.LayerNorm.bias    ├─96
│    └─roberta.encoder.layer.6.intermediate.dense.weight          ├─6,144
│    └─roberta.encoder.layer.6.intermediate.dense.bias            ├─64
│    └─roberta.encoder.layer.6.output.dense.weight                ├─6,144
│    └─roberta.encoder.layer.6.output.dense.bias                  ├─96
│    └─roberta.encoder.layer.6.output.LayerNorm.weight            ├─96
│    └─roberta.encoder.layer.6.output.LayerNorm.bias              ├─96
│    └─roberta.encoder.layer.7.attention.self.query.weight        ├─9,216
│    └─roberta.encoder.layer.7.attention.self.query.bias          ├─96
│    └─roberta.encoder.layer.7.attention.self.key.weight          ├─9,216
│    └─roberta.encoder.layer.7.attention.self.key.bias            ├─96
│    └─roberta.encoder.layer.7.attention.self.value.weight        ├─9,216
│    └─roberta.encoder.layer.7.attention.self.value.bias          ├─96
│    └─roberta.encoder.layer.7.attention.output.dense.weight      ├─9,216
│    └─roberta.encoder.layer.7.attention.output.dense.bias        ├─96
│    └─roberta.encoder.layer.7.attention.output.LayerNorm.weight  ├─96
│    └─roberta.encoder.layer.7.attention.output.LayerNorm.bias    ├─96
│    └─roberta.encoder.layer.7.intermediate.dense.weight          ├─6,144
│    └─roberta.encoder.layer.7.intermediate.dense.bias            ├─64
│    └─roberta.encoder.layer.7.output.dense.weight                ├─6,144
│    └─roberta.encoder.layer.7.output.dense.bias                  ├─96
│    └─roberta.encoder.layer.7.output.LayerNorm.weight            ├─96
│    └─roberta.encoder.layer.7.output.LayerNorm.bias              ├─96
│    └─roberta.encoder.layer.8.attention.self.query.weight        ├─9,216
│    └─roberta.encoder.layer.8.attention.self.query.bias          ├─96
│    └─roberta.encoder.layer.8.attention.self.key.weight          ├─9,216
│    └─roberta.encoder.layer.8.attention.self.key.bias            ├─96
│    └─roberta.encoder.layer.8.attention.self.value.weight        ├─9,216
│    └─roberta.encoder.layer.8.attention.self.value.bias          ├─96
│    └─roberta.encoder.layer.8.attention.output.dense.weight      ├─9,216
│    └─roberta.encoder.layer.8.attention.output.dense.bias        ├─96
│    └─roberta.encoder.layer.8.attention.output.LayerNorm.weight  ├─96
│    └─roberta.encoder.layer.8.attention.output.LayerNorm.bias    ├─96
│    └─roberta.encoder.layer.8.intermediate.dense.weight          ├─6,144
│    └─roberta.encoder.layer.8.intermediate.dense.bias            ├─64
│    └─roberta.encoder.layer.8.output.dense.weight                ├─6,144
│    └─roberta.encoder.layer.8.output.dense.bias                  ├─96
│    └─roberta.encoder.layer.8.output.LayerNorm.weight            ├─96
│    └─roberta.encoder.layer.8.output.LayerNorm.bias              ├─96
│    └─roberta.encoder.layer.9.attention.self.query.weight        ├─9,216
│    └─roberta.encoder.layer.9.attention.self.query.bias          ├─96
│    └─roberta.encoder.layer.9.attention.self.key.weight          ├─9,216
│    └─roberta.encoder.layer.9.attention.self.key.bias            ├─96
│    └─roberta.encoder.layer.9.attention.self.value.weight        ├─9,216
│    └─roberta.encoder.layer.9.attention.self.value.bias          ├─96
│    └─roberta.encoder.layer.9.attention.output.dense.weight      ├─9,216
│    └─roberta.encoder.layer.9.attention.output.dense.bias        ├─96
│    └─roberta.encoder.layer.9.attention.output.LayerNorm.weight  ├─96
│    └─roberta.encoder.layer.9.attention.output.LayerNorm.bias    ├─96
│    └─roberta.encoder.layer.9.intermediate.dense.weight          ├─6,144
│    └─roberta.encoder.layer.9.intermediate.dense.bias            ├─64
│    └─roberta.encoder.layer.9.output.dense.weight                ├─6,144
│    └─roberta.encoder.layer.9.output.dense.bias                  ├─96
│    └─roberta.encoder.layer.9.output.LayerNorm.weight            ├─96
│    └─roberta.encoder.layer.9.output.LayerNorm.bias              ├─96
│    └─roberta.encoder.layer.10.attention.self.query.weight       ├─9,216
│    └─roberta.encoder.layer.10.attention.self.query.bias         ├─96
│    └─roberta.encoder.layer.10.attention.self.key.weight         ├─9,216
│    └─roberta.encoder.layer.10.attention.self.key.bias           ├─96
│    └─roberta.encoder.layer.10.attention.self.value.weight       ├─9,216
│    └─roberta.encoder.layer.10.attention.self.value.bias         ├─96
│    └─roberta.encoder.layer.10.attention.output.dense.weight     ├─9,216
│    └─roberta.encoder.layer.10.attention.output.dense.bias       ├─96
│    └─roberta.encoder.layer.10.attention.output.LayerNorm.weight ├─96
│    └─roberta.encoder.layer.10.attention.output.LayerNorm.bias   ├─96
│    └─roberta.encoder.layer.10.intermediate.dense.weight         ├─6,144
│    └─roberta.encoder.layer.10.intermediate.dense.bias           ├─64
│    └─roberta.encoder.layer.10.output.dense.weight               ├─6,144
│    └─roberta.encoder.layer.10.output.dense.bias                 ├─96
│    └─roberta.encoder.layer.10.output.LayerNorm.weight           ├─96
│    └─roberta.encoder.layer.10.output.LayerNorm.bias             ├─96
│    └─roberta.encoder.layer.11.attention.self.query.weight       ├─9,216
│    └─roberta.encoder.layer.11.attention.self.query.bias         ├─96
│    └─roberta.encoder.layer.11.attention.self.key.weight         ├─9,216
│    └─roberta.encoder.layer.11.attention.self.key.bias           ├─96
│    └─roberta.encoder.layer.11.attention.self.value.weight       ├─9,216
│    └─roberta.encoder.layer.11.attention.self.value.bias         ├─96
│    └─roberta.encoder.layer.11.attention.output.dense.weight     ├─9,216
│    └─roberta.encoder.layer.11.attention.output.dense.bias       ├─96
│    └─roberta.encoder.layer.11.attention.output.LayerNorm.weight ├─96
│    └─roberta.encoder.layer.11.attention.output.LayerNorm.bias   ├─96
│    └─roberta.encoder.layer.11.intermediate.dense.weight         ├─6,144
│    └─roberta.encoder.layer.11.intermediate.dense.bias           ├─64
│    └─roberta.encoder.layer.11.output.dense.weight               ├─6,144
│    └─roberta.encoder.layer.11.output.dense.bias                 ├─96
│    └─roberta.encoder.layer.11.output.LayerNorm.weight           ├─96
│    └─roberta.encoder.layer.11.output.LayerNorm.bias             ├─96
│    └─classifier.dense.weight                                    ├─9,216
│    └─classifier.dense.bias                                      ├─96
│    └─classifier.out_proj.weight                                 ├─192
│    └─classifier.out_proj.bias                                   └─2
│    └─RobertaModel: 2-1                                          --
│    │    └─embeddings.word_embeddings.weight                     ├─96,000
│    │    └─embeddings.position_embeddings.weight                 ├─49,344
│    │    └─embeddings.token_type_embeddings.weight               ├─96
│    │    └─embeddings.LayerNorm.weight                           ├─96
│    │    └─embeddings.LayerNorm.bias                             ├─96
│    │    └─encoder.layer.0.attention.self.query.weight           ├─9,216
│    │    └─encoder.layer.0.attention.self.query.bias             ├─96
│    │    └─encoder.layer.0.attention.self.key.weight             ├─9,216
│    │    └─encoder.layer.0.attention.self.key.bias               ├─96
│    │    └─encoder.layer.0.attention.self.value.weight           ├─9,216
│    │    └─encoder.layer.0.attention.self.value.bias             ├─96
│    │    └─encoder.layer.0.attention.output.dense.weight         ├─9,216
│    │    └─encoder.layer.0.attention.output.dense.bias           ├─96
│    │    └─encoder.layer.0.attention.output.LayerNorm.weight     ├─96
│    │    └─encoder.layer.0.attention.output.LayerNorm.bias       ├─96
│    │    └─encoder.layer.0.intermediate.dense.weight             ├─6,144
│    │    └─encoder.layer.0.intermediate.dense.bias               ├─64
│    │    └─encoder.layer.0.output.dense.weight                   ├─6,144
│    │    └─encoder.layer.0.output.dense.bias                     ├─96
│    │    └─encoder.layer.0.output.LayerNorm.weight               ├─96
│    │    └─encoder.layer.0.output.LayerNorm.bias                 ├─96
│    │    └─encoder.layer.1.attention.self.query.weight           ├─9,216
│    │    └─encoder.layer.1.attention.self.query.bias             ├─96
│    │    └─encoder.layer.1.attention.self.key.weight             ├─9,216
│    │    └─encoder.layer.1.attention.self.key.bias               ├─96
│    │    └─encoder.layer.1.attention.self.value.weight           ├─9,216
│    │    └─encoder.layer.1.attention.self.value.bias             ├─96
│    │    └─encoder.layer.1.attention.output.dense.weight         ├─9,216
│    │    └─encoder.layer.1.attention.output.dense.bias           ├─96
│    │    └─encoder.layer.1.attention.output.LayerNorm.weight     ├─96
│    │    └─encoder.layer.1.attention.output.LayerNorm.bias       ├─96
│    │    └─encoder.layer.1.intermediate.dense.weight             ├─6,144
│    │    └─encoder.layer.1.intermediate.dense.bias               ├─64
│    │    └─encoder.layer.1.output.dense.weight                   ├─6,144
│    │    └─encoder.layer.1.output.dense.bias                     ├─96
│    │    └─encoder.layer.1.output.LayerNorm.weight               ├─96
│    │    └─encoder.layer.1.output.LayerNorm.bias                 ├─96
│    │    └─encoder.layer.2.attention.self.query.weight           ├─9,216
08/29/2024 16:02:05 - INFO - __main__ -   Creating features from file at ../dataset/valid.jsonl 
│    │    └─encoder.layer.2.attention.self.query.bias             ├─96
│    │    └─encoder.layer.2.attention.self.key.weight             ├─9,216
│    │    └─encoder.layer.2.attention.self.key.bias               ├─96
│    │    └─encoder.layer.2.attention.self.value.weight           ├─9,216
│    │    └─encoder.layer.2.attention.self.value.bias             ├─96
│    │    └─encoder.layer.2.attention.output.dense.weight         ├─9,216
│    │    └─encoder.layer.2.attention.output.dense.bias           ├─96
│    │    └─encoder.layer.2.attention.output.LayerNorm.weight     ├─96
│    │    └─encoder.layer.2.attention.output.LayerNorm.bias       ├─96
│    │    └─encoder.layer.2.intermediate.dense.weight             ├─6,144
│    │    └─encoder.layer.2.intermediate.dense.bias               ├─64
│    │    └─encoder.layer.2.output.dense.weight                   ├─6,144
│    │    └─encoder.layer.2.output.dense.bias                     ├─96
│    │    └─encoder.layer.2.output.LayerNorm.weight               ├─96
│    │    └─encoder.layer.2.output.LayerNorm.bias                 ├─96
│    │    └─encoder.layer.3.attention.self.query.weight           ├─9,216
│    │    └─encoder.layer.3.attention.self.query.bias             ├─96
│    │    └─encoder.layer.3.attention.self.key.weight             ├─9,216
│    │    └─encoder.layer.3.attention.self.key.bias               ├─96
│    │    └─encoder.layer.3.attention.self.value.weight           ├─9,216
│    │    └─encoder.layer.3.attention.self.value.bias             ├─96
│    │    └─encoder.layer.3.attention.output.dense.weight         ├─9,216
│    │    └─encoder.layer.3.attention.output.dense.bias           ├─96
│    │    └─encoder.layer.3.attention.output.LayerNorm.weight     ├─96
│    │    └─encoder.layer.3.attention.output.LayerNorm.bias       ├─96
│    │    └─encoder.layer.3.intermediate.dense.weight             ├─6,144
│    │    └─encoder.layer.3.intermediate.dense.bias               ├─64
│    │    └─encoder.layer.3.output.dense.weight                   ├─6,144
│    │    └─encoder.layer.3.output.dense.bias                     ├─96
│    │    └─encoder.layer.3.output.LayerNorm.weight               ├─96
│    │    └─encoder.layer.3.output.LayerNorm.bias                 ├─96
│    │    └─encoder.layer.4.attention.self.query.weight           ├─9,216
│    │    └─encoder.layer.4.attention.self.query.bias             ├─96
│    │    └─encoder.layer.4.attention.self.key.weight             ├─9,216
│    │    └─encoder.layer.4.attention.self.key.bias               ├─96
│    │    └─encoder.layer.4.attention.self.value.weight           ├─9,216
│    │    └─encoder.layer.4.attention.self.value.bias             ├─96
│    │    └─encoder.layer.4.attention.output.dense.weight         ├─9,216
│    │    └─encoder.layer.4.attention.output.dense.bias           ├─96
│    │    └─encoder.layer.4.attention.output.LayerNorm.weight     ├─96
│    │    └─encoder.layer.4.attention.output.LayerNorm.bias       ├─96
│    │    └─encoder.layer.4.intermediate.dense.weight             ├─6,144
│    │    └─encoder.layer.4.intermediate.dense.bias               ├─64
│    │    └─encoder.layer.4.output.dense.weight                   ├─6,144
│    │    └─encoder.layer.4.output.dense.bias                     ├─96
│    │    └─encoder.layer.4.output.LayerNorm.weight               ├─96
│    │    └─encoder.layer.4.output.LayerNorm.bias                 ├─96
│    │    └─encoder.layer.5.attention.self.query.weight           ├─9,216
│    │    └─encoder.layer.5.attention.self.query.bias             ├─96
│    │    └─encoder.layer.5.attention.self.key.weight             ├─9,216
│    │    └─encoder.layer.5.attention.self.key.bias               ├─96
│    │    └─encoder.layer.5.attention.self.value.weight           ├─9,216
│    │    └─encoder.layer.5.attention.self.value.bias             ├─96
│    │    └─encoder.layer.5.attention.output.dense.weight         ├─9,216
│    │    └─encoder.layer.5.attention.output.dense.bias           ├─96
│    │    └─encoder.layer.5.attention.output.LayerNorm.weight     ├─96
│    │    └─encoder.layer.5.attention.output.LayerNorm.bias       ├─96
│    │    └─encoder.layer.5.intermediate.dense.weight             ├─6,144
│    │    └─encoder.layer.5.intermediate.dense.bias               ├─64
│    │    └─encoder.layer.5.output.dense.weight                   ├─6,144
│    │    └─encoder.layer.5.output.dense.bias                     ├─96
│    │    └─encoder.layer.5.output.LayerNorm.weight               ├─96
│    │    └─encoder.layer.5.output.LayerNorm.bias                 ├─96
│    │    └─encoder.layer.6.attention.self.query.weight           ├─9,216
│    │    └─encoder.layer.6.attention.self.query.bias             ├─96
│    │    └─encoder.layer.6.attention.self.key.weight             ├─9,216
│    │    └─encoder.layer.6.attention.self.key.bias               ├─96
│    │    └─encoder.layer.6.attention.self.value.weight           ├─9,216
│    │    └─encoder.layer.6.attention.self.value.bias             ├─96
│    │    └─encoder.layer.6.attention.output.dense.weight         ├─9,216
│    │    └─encoder.layer.6.attention.output.dense.bias           ├─96
│    │    └─encoder.layer.6.attention.output.LayerNorm.weight     ├─96
│    │    └─encoder.layer.6.attention.output.LayerNorm.bias       ├─96
│    │    └─encoder.layer.6.intermediate.dense.weight             ├─6,144
│    │    └─encoder.layer.6.intermediate.dense.bias               ├─64
│    │    └─encoder.layer.6.output.dense.weight                   ├─6,144
│    │    └─encoder.layer.6.output.dense.bias                     ├─96
│    │    └─encoder.layer.6.output.LayerNorm.weight               ├─96
│    │    └─encoder.layer.6.output.LayerNorm.bias                 ├─96
│    │    └─encoder.layer.7.attention.self.query.weight           ├─9,216
│    │    └─encoder.layer.7.attention.self.query.bias             ├─96
│    │    └─encoder.layer.7.attention.self.key.weight             ├─9,216
│    │    └─encoder.layer.7.attention.self.key.bias               ├─96
│    │    └─encoder.layer.7.attention.self.value.weight           ├─9,216
│    │    └─encoder.layer.7.attention.self.value.bias             ├─96
│    │    └─encoder.layer.7.attention.output.dense.weight         ├─9,216
│    │    └─encoder.layer.7.attention.output.dense.bias           ├─96
│    │    └─encoder.layer.7.attention.output.LayerNorm.weight     ├─96
│    │    └─encoder.layer.7.attention.output.LayerNorm.bias       ├─96
│    │    └─encoder.layer.7.intermediate.dense.weight             ├─6,144
│    │    └─encoder.layer.7.intermediate.dense.bias               ├─64
│    │    └─encoder.layer.7.output.dense.weight                   ├─6,144
│    │    └─encoder.layer.7.output.dense.bias                     ├─96
│    │    └─encoder.layer.7.output.LayerNorm.weight               ├─96
│    │    └─encoder.layer.7.output.LayerNorm.bias                 ├─96
│    │    └─encoder.layer.8.attention.self.query.weight           ├─9,216
│    │    └─encoder.layer.8.attention.self.query.bias             ├─96
│    │    └─encoder.layer.8.attention.self.key.weight             ├─9,216
│    │    └─encoder.layer.8.attention.self.key.bias               ├─96
│    │    └─encoder.layer.8.attention.self.value.weight           ├─9,216
│    │    └─encoder.layer.8.attention.self.value.bias             ├─96
│    │    └─encoder.layer.8.attention.output.dense.weight         ├─9,216
│    │    └─encoder.layer.8.attention.output.dense.bias           ├─96
│    │    └─encoder.layer.8.attention.output.LayerNorm.weight     ├─96
│    │    └─encoder.layer.8.attention.output.LayerNorm.bias       ├─96
│    │    └─encoder.layer.8.intermediate.dense.weight             ├─6,144
│    │    └─encoder.layer.8.intermediate.dense.bias               ├─64
│    │    └─encoder.layer.8.output.dense.weight                   ├─6,144
│    │    └─encoder.layer.8.output.dense.bias                     ├─96
│    │    └─encoder.layer.8.output.LayerNorm.weight               ├─96
│    │    └─encoder.layer.8.output.LayerNorm.bias                 ├─96
│    │    └─encoder.layer.9.attention.self.query.weight           ├─9,216
│    │    └─encoder.layer.9.attention.self.query.bias             ├─96
│    │    └─encoder.layer.9.attention.self.key.weight             ├─9,216
│    │    └─encoder.layer.9.attention.self.key.bias               ├─96
│    │    └─encoder.layer.9.attention.self.value.weight           ├─9,216
│    │    └─encoder.layer.9.attention.self.value.bias             ├─96
│    │    └─encoder.layer.9.attention.output.dense.weight         ├─9,216
│    │    └─encoder.layer.9.attention.output.dense.bias           ├─96
│    │    └─encoder.layer.9.attention.output.LayerNorm.weight     ├─96
│    │    └─encoder.layer.9.attention.output.LayerNorm.bias       ├─96
│    │    └─encoder.layer.9.intermediate.dense.weight             ├─6,144
│    │    └─encoder.layer.9.intermediate.dense.bias               ├─64
│    │    └─encoder.layer.9.output.dense.weight                   ├─6,144
│    │    └─encoder.layer.9.output.dense.bias                     ├─96
│    │    └─encoder.layer.9.output.LayerNorm.weight               ├─96
│    │    └─encoder.layer.9.output.LayerNorm.bias                 ├─96
│    │    └─encoder.layer.10.attention.self.query.weight          ├─9,216
│    │    └─encoder.layer.10.attention.self.query.bias            ├─96
│    │    └─encoder.layer.10.attention.self.key.weight            ├─9,216
│    │    └─encoder.layer.10.attention.self.key.bias              ├─96
│    │    └─encoder.layer.10.attention.self.value.weight          ├─9,216
│    │    └─encoder.layer.10.attention.self.value.bias            ├─96
│    │    └─encoder.layer.10.attention.output.dense.weight        ├─9,216
│    │    └─encoder.layer.10.attention.output.dense.bias          ├─96
│    │    └─encoder.layer.10.attention.output.LayerNorm.weight    ├─96
│    │    └─encoder.layer.10.attention.output.LayerNorm.bias      ├─96
│    │    └─encoder.layer.10.intermediate.dense.weight            ├─6,144
│    │    └─encoder.layer.10.intermediate.dense.bias              ├─64
│    │    └─encoder.layer.10.output.dense.weight                  ├─6,144
│    │    └─encoder.layer.10.output.dense.bias                    ├─96
│    │    └─encoder.layer.10.output.LayerNorm.weight              ├─96
│    │    └─encoder.layer.10.output.LayerNorm.bias                ├─96
│    │    └─encoder.layer.11.attention.self.query.weight          ├─9,216
│    │    └─encoder.layer.11.attention.self.query.bias            ├─96
│    │    └─encoder.layer.11.attention.self.key.weight            ├─9,216
│    │    └─encoder.layer.11.attention.self.key.bias              ├─96
│    │    └─encoder.layer.11.attention.self.value.weight          ├─9,216
│    │    └─encoder.layer.11.attention.self.value.bias            ├─96
│    │    └─encoder.layer.11.attention.output.dense.weight        ├─9,216
│    │    └─encoder.layer.11.attention.output.dense.bias          ├─96
│    │    └─encoder.layer.11.attention.output.LayerNorm.weight    ├─96
│    │    └─encoder.layer.11.attention.output.LayerNorm.bias      ├─96
│    │    └─encoder.layer.11.intermediate.dense.weight            ├─6,144
│    │    └─encoder.layer.11.intermediate.dense.bias              ├─64
│    │    └─encoder.layer.11.output.dense.weight                  ├─6,144
│    │    └─encoder.layer.11.output.dense.bias                    ├─96
│    │    └─encoder.layer.11.output.LayerNorm.weight              ├─96
│    │    └─encoder.layer.11.output.LayerNorm.bias                └─96
│    │    └─RobertaEmbeddings: 3-1                                145,632
│    │    │    └─word_embeddings.weight                           ├─96,000
│    │    │    └─position_embeddings.weight                       ├─49,344
│    │    │    └─token_type_embeddings.weight                     ├─96
│    │    │    └─LayerNorm.weight                                 ├─96
│    │    │    └─LayerNorm.bias                                   └─96
│    │    └─RobertaEncoder: 3-2                                   600,960
│    │    │    └─layer.0.attention.self.query.weight              ├─9,216
│    │    │    └─layer.0.attention.self.query.bias                ├─96
│    │    │    └─layer.0.attention.self.key.weight                ├─9,216
│    │    │    └─layer.0.attention.self.key.bias                  ├─96
│    │    │    └─layer.0.attention.self.value.weight              ├─9,216
│    │    │    └─layer.0.attention.self.value.bias                ├─96
│    │    │    └─layer.0.attention.output.dense.weight            ├─9,216
│    │    │    └─layer.0.attention.output.dense.bias              ├─96
│    │    │    └─layer.0.attention.output.LayerNorm.weight        ├─96
│    │    │    └─layer.0.attention.output.LayerNorm.bias          ├─96
│    │    │    └─layer.0.intermediate.dense.weight                ├─6,144
│    │    │    └─layer.0.intermediate.dense.bias                  ├─64
│    │    │    └─layer.0.output.dense.weight                      ├─6,144
│    │    │    └─layer.0.output.dense.bias                        ├─96
│    │    │    └─layer.0.output.LayerNorm.weight                  ├─96
│    │    │    └─layer.0.output.LayerNorm.bias                    ├─96
│    │    │    └─layer.1.attention.self.query.weight              ├─9,216
│    │    │    └─layer.1.attention.self.query.bias                ├─96
│    │    │    └─layer.1.attention.self.key.weight                ├─9,216
│    │    │    └─layer.1.attention.self.key.bias                  ├─96
│    │    │    └─layer.1.attention.self.value.weight              ├─9,216
│    │    │    └─layer.1.attention.self.value.bias                ├─96
│    │    │    └─layer.1.attention.output.dense.weight            ├─9,216
│    │    │    └─layer.1.attention.output.dense.bias              ├─96
│    │    │    └─layer.1.attention.output.LayerNorm.weight        ├─96
│    │    │    └─layer.1.attention.output.LayerNorm.bias          ├─96
│    │    │    └─layer.1.intermediate.dense.weight                ├─6,144
│    │    │    └─layer.1.intermediate.dense.bias                  ├─64
│    │    │    └─layer.1.output.dense.weight                      ├─6,144
│    │    │    └─layer.1.output.dense.bias                        ├─96
│    │    │    └─layer.1.output.LayerNorm.weight                  ├─96
│    │    │    └─layer.1.output.LayerNorm.bias                    ├─96
│    │    │    └─layer.2.attention.self.query.weight              ├─9,216
│    │    │    └─layer.2.attention.self.query.bias                ├─96
│    │    │    └─layer.2.attention.self.key.weight                ├─9,216
│    │    │    └─layer.2.attention.self.key.bias                  ├─96
│    │    │    └─layer.2.attention.self.value.weight              ├─9,216
│    │    │    └─layer.2.attention.self.value.bias                ├─96
│    │    │    └─layer.2.attention.output.dense.weight            ├─9,216
│    │    │    └─layer.2.attention.output.dense.bias              ├─96
│    │    │    └─layer.2.attention.output.LayerNorm.weight        ├─96
│    │    │    └─layer.2.attention.output.LayerNorm.bias          ├─96
│    │    │    └─layer.2.intermediate.dense.weight                ├─6,144
│    │    │    └─layer.2.intermediate.dense.bias                  ├─64
│    │    │    └─layer.2.output.dense.weight                      ├─6,144
│    │    │    └─layer.2.output.dense.bias                        ├─96
│    │    │    └─layer.2.output.LayerNorm.weight                  ├─96
│    │    │    └─layer.2.output.LayerNorm.bias                    ├─96
│    │    │    └─layer.3.attention.self.query.weight              ├─9,216
│    │    │    └─layer.3.attention.self.query.bias                ├─96
│    │    │    └─layer.3.attention.self.key.weight                ├─9,216
│    │    │    └─layer.3.attention.self.key.bias                  ├─96
│    │    │    └─layer.3.attention.self.value.weight              ├─9,216
│    │    │    └─layer.3.attention.self.value.bias                ├─96
│    │    │    └─layer.3.attention.output.dense.weight            ├─9,216
│    │    │    └─layer.3.attention.output.dense.bias              ├─96
│    │    │    └─layer.3.attention.output.LayerNorm.weight        ├─96
│    │    │    └─layer.3.attention.output.LayerNorm.bias          ├─96
│    │    │    └─layer.3.intermediate.dense.weight                ├─6,144
│    │    │    └─layer.3.intermediate.dense.bias                  ├─64
│    │    │    └─layer.3.output.dense.weight                      ├─6,144
│    │    │    └─layer.3.output.dense.bias                        ├─96
│    │    │    └─layer.3.output.LayerNorm.weight                  ├─96
│    │    │    └─layer.3.output.LayerNorm.bias                    ├─96
│    │    │    └─layer.4.attention.self.query.weight              ├─9,216
│    │    │    └─layer.4.attention.self.query.bias                ├─96
│    │    │    └─layer.4.attention.self.key.weight                ├─9,216
│    │    │    └─layer.4.attention.self.key.bias                  ├─96
│    │    │    └─layer.4.attention.self.value.weight              ├─9,216
│    │    │    └─layer.4.attention.self.value.bias                ├─96
│    │    │    └─layer.4.attention.output.dense.weight            ├─9,216
│    │    │    └─layer.4.attention.output.dense.bias              ├─96
│    │    │    └─layer.4.attention.output.LayerNorm.weight        ├─96
│    │    │    └─layer.4.attention.output.LayerNorm.bias          ├─96
│    │    │    └─layer.4.intermediate.dense.weight                ├─6,144
│    │    │    └─layer.4.intermediate.dense.bias                  ├─64
│    │    │    └─layer.4.output.dense.weight                      ├─6,144
│    │    │    └─layer.4.output.dense.bias                        ├─96
│    │    │    └─layer.4.output.LayerNorm.weight                  ├─96
│    │    │    └─layer.4.output.LayerNorm.bias                    ├─96
│    │    │    └─layer.5.attention.self.query.weight              ├─9,216
│    │    │    └─layer.5.attention.self.query.bias                ├─96
│    │    │    └─layer.5.attention.self.key.weight                ├─9,216
│    │    │    └─layer.5.attention.self.key.bias                  ├─96
│    │    │    └─layer.5.attention.self.value.weight              ├─9,216
│    │    │    └─layer.5.attention.self.value.bias                ├─96
│    │    │    └─layer.5.attention.output.dense.weight            ├─9,216
│    │    │    └─layer.5.attention.output.dense.bias              ├─96
│    │    │    └─layer.5.attention.output.LayerNorm.weight        ├─96
│    │    │    └─layer.5.attention.output.LayerNorm.bias          ├─96
│    │    │    └─layer.5.intermediate.dense.weight                ├─6,144
│    │    │    └─layer.5.intermediate.dense.bias                  ├─64
│    │    │    └─layer.5.output.dense.weight                      ├─6,144
│    │    │    └─layer.5.output.dense.bias                        ├─96
│    │    │    └─layer.5.output.LayerNorm.weight                  ├─96
│    │    │    └─layer.5.output.LayerNorm.bias                    ├─96
│    │    │    └─layer.6.attention.self.query.weight              ├─9,216
│    │    │    └─layer.6.attention.self.query.bias                ├─96
│    │    │    └─layer.6.attention.self.key.weight                ├─9,216
│    │    │    └─layer.6.attention.self.key.bias                  ├─96
│    │    │    └─layer.6.attention.self.value.weight              ├─9,216
│    │    │    └─layer.6.attention.self.value.bias                ├─96
│    │    │    └─layer.6.attention.output.dense.weight            ├─9,216
│    │    │    └─layer.6.attention.output.dense.bias              ├─96
│    │    │    └─layer.6.attention.output.LayerNorm.weight        ├─96
│    │    │    └─layer.6.attention.output.LayerNorm.bias          ├─96
│    │    │    └─layer.6.intermediate.dense.weight                ├─6,144
│    │    │    └─layer.6.intermediate.dense.bias                  ├─64
│    │    │    └─layer.6.output.dense.weight                      ├─6,144
│    │    │    └─layer.6.output.dense.bias                        ├─96
│    │    │    └─layer.6.output.LayerNorm.weight                  ├─96
│    │    │    └─layer.6.output.LayerNorm.bias                    ├─96
│    │    │    └─layer.7.attention.self.query.weight              ├─9,216
│    │    │    └─layer.7.attention.self.query.bias                ├─96
│    │    │    └─layer.7.attention.self.key.weight                ├─9,216
│    │    │    └─layer.7.attention.self.key.bias                  ├─96
│    │    │    └─layer.7.attention.self.value.weight              ├─9,216
│    │    │    └─layer.7.attention.self.value.bias                ├─96
│    │    │    └─layer.7.attention.output.dense.weight            ├─9,216
│    │    │    └─layer.7.attention.output.dense.bias              ├─96
│    │    │    └─layer.7.attention.output.LayerNorm.weight        ├─96
│    │    │    └─layer.7.attention.output.LayerNorm.bias          ├─96
│    │    │    └─layer.7.intermediate.dense.weight                ├─6,144
│    │    │    └─layer.7.intermediate.dense.bias                  ├─64
│    │    │    └─layer.7.output.dense.weight                      ├─6,144
│    │    │    └─layer.7.output.dense.bias                        ├─96
│    │    │    └─layer.7.output.LayerNorm.weight                  ├─96
│    │    │    └─layer.7.output.LayerNorm.bias                    ├─96
│    │    │    └─layer.8.attention.self.query.weight              ├─9,216
│    │    │    └─layer.8.attention.self.query.bias                ├─96
│    │    │    └─layer.8.attention.self.key.weight                ├─9,216
│    │    │    └─layer.8.attention.self.key.bias                  ├─96
│    │    │    └─layer.8.attention.self.value.weight              ├─9,216
│    │    │    └─layer.8.attention.self.value.bias                ├─96
│    │    │    └─layer.8.attention.output.dense.weight            ├─9,216
│    │    │    └─layer.8.attention.output.dense.bias              ├─96
│    │    │    └─layer.8.attention.output.LayerNorm.weight        ├─96
│    │    │    └─layer.8.attention.output.LayerNorm.bias          ├─96
│    │    │    └─layer.8.intermediate.dense.weight                ├─6,144
│    │    │    └─layer.8.intermediate.dense.bias                  ├─64
│    │    │    └─layer.8.output.dense.weight                      ├─6,144
│    │    │    └─layer.8.output.dense.bias                        ├─96
│    │    │    └─layer.8.output.LayerNorm.weight                  ├─96
│    │    │    └─layer.8.output.LayerNorm.bias                    ├─96
│    │    │    └─layer.9.attention.self.query.weight              ├─9,216
│    │    │    └─layer.9.attention.self.query.bias                ├─96
│    │    │    └─layer.9.attention.self.key.weight                ├─9,216
│    │    │    └─layer.9.attention.self.key.bias                  ├─96
│    │    │    └─layer.9.attention.self.value.weight              ├─9,216
│    │    │    └─layer.9.attention.self.value.bias                ├─96
│    │    │    └─layer.9.attention.output.dense.weight            ├─9,216
│    │    │    └─layer.9.attention.output.dense.bias              ├─96
│    │    │    └─layer.9.attention.output.LayerNorm.weight        ├─96
│    │    │    └─layer.9.attention.output.LayerNorm.bias          ├─96
│    │    │    └─layer.9.intermediate.dense.weight                ├─6,144
│    │    │    └─layer.9.intermediate.dense.bias                  ├─64
│    │    │    └─layer.9.output.dense.weight                      ├─6,144
│    │    │    └─layer.9.output.dense.bias                        ├─96
│    │    │    └─layer.9.output.LayerNorm.weight                  ├─96
│    │    │    └─layer.9.output.LayerNorm.bias                    ├─96
│    │    │    └─layer.10.attention.self.query.weight             ├─9,216
│    │    │    └─layer.10.attention.self.query.bias               ├─96
│    │    │    └─layer.10.attention.self.key.weight               ├─9,216
│    │    │    └─layer.10.attention.self.key.bias                 ├─96
│    │    │    └─layer.10.attention.self.value.weight             ├─9,216
│    │    │    └─layer.10.attention.self.value.bias               ├─96
│    │    │    └─layer.10.attention.output.dense.weight           ├─9,216
│    │    │    └─layer.10.attention.output.dense.bias             ├─96
│    │    │    └─layer.10.attention.output.LayerNorm.weight       ├─96
│    │    │    └─layer.10.attention.output.LayerNorm.bias         ├─96
│    │    │    └─layer.10.intermediate.dense.weight               ├─6,144
│    │    │    └─layer.10.intermediate.dense.bias                 ├─64
│    │    │    └─layer.10.output.dense.weight                     ├─6,144
│    │    │    └─layer.10.output.dense.bias                       ├─96
│    │    │    └─layer.10.output.LayerNorm.weight                 ├─96
│    │    │    └─layer.10.output.LayerNorm.bias                   ├─96
│    │    │    └─layer.11.attention.self.query.weight             ├─9,216
│    │    │    └─layer.11.attention.self.query.bias               ├─96
│    │    │    └─layer.11.attention.self.key.weight               ├─9,216
│    │    │    └─layer.11.attention.self.key.bias                 ├─96
│    │    │    └─layer.11.attention.self.value.weight             ├─9,216
│    │    │    └─layer.11.attention.self.value.bias               ├─96
│    │    │    └─layer.11.attention.output.dense.weight           ├─9,216
│    │    │    └─layer.11.attention.output.dense.bias             ├─96
│    │    │    └─layer.11.attention.output.LayerNorm.weight       ├─96
│    │    │    └─layer.11.attention.output.LayerNorm.bias         ├─96
│    │    │    └─layer.11.intermediate.dense.weight               ├─6,144
│    │    │    └─layer.11.intermediate.dense.bias                 ├─64
│    │    │    └─layer.11.output.dense.weight                     ├─6,144
│    │    │    └─layer.11.output.dense.bias                       ├─96
│    │    │    └─layer.11.output.LayerNorm.weight                 ├─96
│    │    │    └─layer.11.output.LayerNorm.bias                   └─96
│    └─RobertaClassificationHead: 2-2                             --
│    │    └─dense.weight                                          ├─9,216
│    │    └─dense.bias                                            ├─96
│    │    └─out_proj.weight                                       ├─192
│    │    └─out_proj.bias                                         └─2
│    │    └─Linear: 3-3                                           9,312
│    │    │    └─weight                                           ├─9,216
│    │    │    └─bias                                             └─96
│    │    └─Dropout: 3-4                                          --
│    │    └─Linear: 3-5                                           194
│    │    │    └─weight                                           ├─192
│    │    │    └─bias                                             └─2
├─Dropout: 1-2                                                    --
==========================================================================================
Total params: 756,098
Trainable params: 756,098
Non-trainable params: 0
08/29/2024 16:02:06 - INFO - __main__ -   Loading vocabulary from file ../dataset/BPE_1000.json
==========================================================================================
  0%|          | 0/2732 [00:00<?, ?it/s]  3%|▎         | 70/2732 [00:00<00:03, 698.68it/s]  5%|▌         | 140/2732 [00:00<00:04, 607.95it/s]  7%|▋         | 202/2732 [00:00<00:07, 333.46it/s] 10%|▉         | 271/2732 [00:00<00:05, 418.46it/s] 12%|█▏        | 333/2732 [00:00<00:05, 469.44it/s] 14%|█▍        | 389/2732 [00:00<00:04, 471.12it/s] 16%|█▌        | 442/2732 [00:00<00:04, 461.04it/s] 19%|█▉        | 517/2732 [00:01<00:04, 537.01it/s] 21%|██        | 575/2732 [00:01<00:03, 547.93it/s] 23%|██▎       | 633/2732 [00:01<00:04, 482.90it/s] 25%|██▌       | 685/2732 [00:01<00:04, 451.39it/s] 27%|██▋       | 733/2732 [00:01<00:04, 454.51it/s] 29%|██▊       | 781/2732 [00:01<00:04, 459.48it/s] 31%|███       | 845/2732 [00:01<00:03, 507.65it/s] 33%|███▎      | 898/2732 [00:01<00:03, 511.80it/s] 35%|███▍      | 951/2732 [00:02<00:03, 453.91it/s] 37%|███▋      | 999/2732 [00:02<00:04, 417.60it/s] 39%|███▊      | 1056/2732 [00:02<00:03, 455.18it/s] 40%|████      | 1104/2732 [00:02<00:03, 446.95it/s] 42%|████▏     | 1157/2732 [00:02<00:03, 469.05it/s] 45%|████▍     | 1221/2732 [00:02<00:02, 516.19it/s] 47%|████▋     | 1274/2732 [00:02<00:03, 481.28it/s] 49%|████▊     | 1328/2732 [00:02<00:02, 497.10it/s] 51%|█████     | 1381/2732 [00:02<00:02, 503.89it/s] 53%|█████▎    | 1435/2732 [00:03<00:02, 505.85it/s] 54%|█████▍    | 1488/2732 [00:03<00:02, 511.33it/s] 57%|█████▋    | 1552/2732 [00:03<00:02, 548.42it/s] 59%|█████▉    | 1608/2732 [00:03<00:02, 476.25it/s] 61%|██████    | 1658/2732 [00:03<00:02, 458.73it/s] 62%|██████▏   | 1706/2732 [00:03<00:02, 409.54it/s] 64%|██████▍   | 1749/2732 [00:03<00:02, 412.49it/s] 67%|██████▋   | 1817/2732 [00:03<00:01, 482.43it/s] 69%|██████▊   | 1877/2732 [00:03<00:01, 511.95it/s] 71%|███████   | 1937/2732 [00:04<00:01, 526.79it/s] 73%|███████▎  | 1991/2732 [00:04<00:01, 519.43it/s] 76%|███████▌  | 2078/2732 [00:04<00:01, 617.42it/s] 80%|███████▉  | 2183/2732 [00:04<00:00, 741.09it/s] 84%|████████▍ | 2302/2732 [00:04<00:00, 869.58it/s] 88%|████████▊ | 2391/2732 [00:04<00:00, 851.80it/s] 92%|█████████▏| 2505/2732 [00:04<00:00, 934.60it/s] 95%|█████████▌| 2600/2732 [00:04<00:00, 913.86it/s]100%|█████████▉| 2726/2732 [00:04<00:00, 1012.18it/s]100%|██████████| 2732/2732 [00:04<00:00, 559.99it/s] 
08/29/2024 16:02:11 - INFO - __main__ -   ***** Running evaluation *****
08/29/2024 16:02:11 - INFO - __main__ -     Num examples = 2732
08/29/2024 16:02:11 - INFO - __main__ -     Batch size = 64
08/29/2024 16:03:18 - INFO - __main__ -   Average time: 1.117449777070866
08/29/2024 16:03:18 - INFO - __main__ -   ***** Eval results *****
08/29/2024 16:03:18 - INFO - __main__ -     eval_acc = 0.6014
08/29/2024 16:03:18 - INFO - __main__ -     eval_loss = 0.6454
08/29/2024 16:03:26 - INFO - __main__ -   Creating features from file at ../dataset/test.jsonl 
08/29/2024 16:03:26 - INFO - __main__ -   Loading vocabulary from file ../dataset/BPE_1000.json
  0%|          | 0/2732 [00:00<?, ?it/s]  2%|▏         | 53/2732 [00:00<00:08, 313.66it/s]  5%|▌         | 143/2732 [00:00<00:04, 579.81it/s]  8%|▊         | 219/2732 [00:00<00:03, 641.26it/s] 12%|█▏        | 320/2732 [00:00<00:03, 765.66it/s] 15%|█▌        | 414/2732 [00:00<00:02, 822.39it/s] 19%|█▉        | 515/2732 [00:00<00:02, 882.89it/s] 22%|██▏       | 606/2732 [00:00<00:02, 841.98it/s] 25%|██▌       | 693/2732 [00:00<00:02, 846.75it/s] 29%|██▊       | 779/2732 [00:01<00:02, 782.53it/s] 32%|███▏      | 874/2732 [00:01<00:02, 828.79it/s] 35%|███▌      | 962/2732 [00:01<00:02, 837.21it/s] 38%|███▊      | 1047/2732 [00:01<00:02, 789.00it/s] 42%|████▏     | 1152/2732 [00:01<00:01, 861.68it/s] 46%|████▌     | 1261/2732 [00:01<00:01, 926.25it/s] 50%|████▉     | 1356/2732 [00:01<00:01, 904.50it/s] 53%|█████▎    | 1450/2732 [00:01<00:01, 914.53it/s] 57%|█████▋    | 1562/2732 [00:01<00:01, 952.40it/s] 61%|██████    | 1658/2732 [00:01<00:01, 951.75it/s] 64%|██████▍   | 1761/2732 [00:02<00:00, 972.64it/s] 68%|██████▊   | 1866/2732 [00:02<00:00, 994.63it/s] 72%|███████▏  | 1966/2732 [00:02<00:00, 975.91it/s] 76%|███████▌  | 2064/2732 [00:02<00:00, 884.49it/s] 79%|███████▉  | 2155/2732 [00:02<00:00, 869.78it/s] 82%|████████▏ | 2244/2732 [00:02<00:00, 821.12it/s] 86%|████████▌ | 2348/2732 [00:02<00:00, 878.77it/s] 90%|█████████ | 2459/2732 [00:02<00:00, 942.34it/s] 94%|█████████▎| 2555/2732 [00:02<00:00, 943.16it/s] 98%|█████████▊| 2674/2732 [00:03<00:00, 1014.18it/s]100%|██████████| 2732/2732 [00:03<00:00, 863.63it/s] 
08/29/2024 16:03:29 - INFO - __main__ -   ***** Running Test *****
08/29/2024 16:03:29 - INFO - __main__ -     Num examples = 2732
08/29/2024 16:03:29 - INFO - __main__ -     Batch size = 64
  0%|          | 0/43 [00:00<?, ?it/s]  2%|▏         | 1/43 [00:01<01:22,  1.96s/it]  5%|▍         | 2/43 [00:04<01:35,  2.33s/it]  7%|▋         | 3/43 [00:07<01:39,  2.48s/it]  9%|▉         | 4/43 [00:10<01:41,  2.60s/it] 12%|█▏        | 5/43 [00:13<01:48,  2.87s/it] 14%|█▍        | 6/43 [00:15<01:43,  2.78s/it] 16%|█▋        | 7/43 [00:18<01:36,  2.69s/it] 19%|█▊        | 8/43 [00:21<01:34,  2.71s/it] 21%|██        | 9/43 [00:24<01:35,  2.81s/it] 23%|██▎       | 10/43 [00:25<01:20,  2.43s/it] 26%|██▌       | 11/43 [00:26<01:03,  2.00s/it] 28%|██▊       | 12/43 [00:28<00:54,  1.77s/it] 30%|███       | 13/43 [00:29<00:46,  1.53s/it] 33%|███▎      | 14/43 [00:30<00:40,  1.41s/it] 35%|███▍      | 15/43 [00:31<00:35,  1.28s/it] 37%|███▋      | 16/43 [00:32<00:32,  1.21s/it] 40%|███▉      | 17/43 [00:33<00:28,  1.11s/it] 42%|████▏     | 18/43 [00:34<00:26,  1.05s/it] 44%|████▍     | 19/43 [00:35<00:25,  1.08s/it] 47%|████▋     | 20/43 [00:36<00:25,  1.10s/it] 49%|████▉     | 21/43 [00:37<00:23,  1.07s/it] 51%|█████     | 22/43 [00:38<00:21,  1.04s/it] 53%|█████▎    | 23/43 [00:39<00:20,  1.04s/it] 56%|█████▌    | 24/43 [00:40<00:21,  1.13s/it] 58%|█████▊    | 25/43 [00:41<00:19,  1.06s/it] 60%|██████    | 26/43 [00:42<00:16,  1.01it/s] 63%|██████▎   | 27/43 [00:43<00:15,  1.06it/s] 65%|██████▌   | 28/43 [00:44<00:13,  1.10it/s] 67%|██████▋   | 29/43 [00:44<00:12,  1.12it/s] 70%|██████▉   | 30/43 [00:45<00:11,  1.12it/s] 72%|███████▏  | 31/43 [00:46<00:11,  1.06it/s] 74%|███████▍  | 32/43 [00:48<00:12,  1.17s/it] 77%|███████▋  | 33/43 [00:50<00:13,  1.32s/it] 79%|███████▉  | 34/43 [00:51<00:12,  1.39s/it] 81%|████████▏ | 35/43 [00:53<00:11,  1.40s/it] 84%|████████▎ | 36/43 [00:55<00:12,  1.72s/it] 86%|████████▌ | 37/43 [00:56<00:09,  1.55s/it] 88%|████████▊ | 38/43 [00:58<00:07,  1.46s/it] 91%|█████████ | 39/43 [00:59<00:05,  1.41s/it] 93%|█████████▎| 40/43 [01:00<00:04,  1.43s/it] 95%|█████████▌| 41/43 [01:02<00:03,  1.54s/it] 98%|█████████▊| 42/43 [01:05<00:01,  1.80s/it]100%|██████████| 43/43 [01:05<00:00,  1.50s/it]100%|██████████| 43/43 [01:05<00:00,  1.53s/it]
08/29/2024 16:04:35 - INFO - __main__ -   Average inference time: 1.4956105309863423
